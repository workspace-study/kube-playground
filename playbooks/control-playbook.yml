---
- hosts: all
  become: true
  tasks:
    # System setup
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install required packages
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
        state: present

    # Disable swap
    - name: Disable swap
      command: swapoff -a
      when: ansible_swaptotal_mb > 0

    - name: Remove swap from fstab
      lineinfile:
        path: /etc/fstab
        regexp: '\sswap\s'
        state: absent

    # Load kernel modules
    - name: Load kernel modules
      modprobe:
        name: "{{ item }}"
      loop:
        - overlay
        - br_netfilter

    - name: Make kernel modules persistent
      copy:
        dest: /etc/modules-load.d/k8s.conf
        content: |
          overlay
          br_netfilter

    # Configure sysctl
    - name: Configure sysctl for Kubernetes
      sysctl:
        name: "{{ item.key }}"
        value: "{{ item.value }}"
        state: present
        sysctl_file: /etc/sysctl.d/k8s.conf
        reload: yes
      loop:
        - { key: 'net.bridge.bridge-nf-call-iptables', value: '1' }
        - { key: 'net.bridge.bridge-nf-call-ip6tables', value: '1' }
        - { key: 'net.ipv4.ip_forward', value: '1' }

    # Install containerd
    - name: Create containerd config directory
      file:
        path: /etc/containerd
        state: directory

    - name: Install containerd
      apt:
        name: containerd
        state: present

    - name: Configure containerd
      shell: containerd config default | tee /etc/containerd/config.toml
      args:
        creates: /etc/containerd/config.toml

    - name: Enable SystemdCgroup in containerd
      lineinfile:
        path: /etc/containerd/config.toml
        regexp: '^\s*SystemdCgroup = false'
        line: '            SystemdCgroup = true'

    - name: Restart containerd
      systemd:
        name: containerd
        state: restarted
        enabled: yes
        daemon_reload: yes

    # Install Kubernetes
    - name: Add Kubernetes apt key
      apt_key:
        url: https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/Release.key
        state: present

    - name: Add Kubernetes repository
      apt_repository:
        repo: deb https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/ /
        state: present

    - name: Install Kubernetes packages
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold Kubernetes packages
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    # Configure routing for dual network interfaces
    - name: Configure routing for dual network interfaces
      copy:
        dest: /etc/sysctl.d/k8s-routing.conf
        content: |
          # Allow IP forwarding between interfaces
          net.ipv4.ip_forward = 1
          # Disable reverse path filtering for flexible routing
          net.ipv4.conf.all.rp_filter = 0
          net.ipv4.conf.default.rp_filter = 0
          net.ipv4.conf.enp0s8.rp_filter = 0
          net.ipv4.conf.enp0s9.rp_filter = 0
      register: routing_config

    - name: Apply sysctl routing settings
      command: sysctl -p /etc/sysctl.d/k8s-routing.conf
      when: routing_config is changed

    # Fix NAT interface routing issue
    - name: Create script to fix NAT routing on boot
      copy:
        dest: /usr/local/bin/fix-nat-routing.sh
        mode: '0755'
        content: |
          #!/bin/bash
          # Remove bad route added by NAT interface DHCP
          ip route del {{ bridge_network }}.1 via 10.0.2.2 dev enp0s3 2>/dev/null || true

    - name: Create systemd service for routing fix
      copy:
        dest: /etc/systemd/system/fix-nat-routing.service
        content: |
          [Unit]
          Description=Fix NAT interface routing
          After=network-online.target
          Wants=network-online.target

          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/fix-nat-routing.sh
          RemainAfterExit=yes

          [Install]
          WantedBy=multi-user.target

    - name: Enable routing fix service
      systemd:
        name: fix-nat-routing
        enabled: yes
        daemon_reload: yes

    # Initialize cluster
    - name: Check if cluster is initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init

    - name: Create kubeadm config
      copy:
        dest: /tmp/kubeadm-config.yaml
        content: |
          apiVersion: kubeadm.k8s.io/v1beta3
          kind: InitConfiguration
          localAPIEndpoint:
            advertiseAddress: {{ node_ip_public }}
            bindPort: 6443
          nodeRegistration:
            name: control-plane
            kubeletExtraArgs:
              cgroup-driver: systemd
              node-ip: {{ node_ip_private }}
          ---
          apiVersion: kubeadm.k8s.io/v1beta3
          kind: ClusterConfiguration
          controlPlaneEndpoint: "{{ node_ip_public }}:6443"
          networking:
            podSubnet: {{ pod_network }}
          apiServer:
            certSANs:
            - "{{ node_ip_public }}"
            - "{{ node_ip_private }}"
            - "control"
            - "control-plane"
            - "localhost"
            - "127.0.0.1"
          ---
          apiVersion: kubelet.config.k8s.io/v1beta1
          kind: KubeletConfiguration
          cgroupDriver: systemd
          evictionHard:
            memory.available: "200Mi"
            nodefs.available: "5%"
            imagefs.available: "5%"
          evictionSoft:
            memory.available: "300Mi"
            nodefs.available: "10%"
            imagefs.available: "10%"
          evictionSoftGracePeriod:
            memory.available: "2m"
            nodefs.available: "1m"
            imagefs.available: "1m"
          systemReserved:
            memory: "256Mi"
            cpu: "250m"
          kubeReserved:
            memory: "256Mi"
            cpu: "250m"
      when: not kubeadm_init.stat.exists

    - name: Initialize Kubernetes cluster
      command: kubeadm init --config /tmp/kubeadm-config.yaml
      when: not kubeadm_init.stat.exists
      register: init_result

    - name: Create .kube directory
      become: false
      file:
        path: /home/vagrant/.kube
        state: directory
        mode: '0755'

    - name: Copy kubeconfig
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/vagrant/.kube/config
        remote_src: yes
        owner: vagrant
        group: vagrant
        mode: '0600'

    # Install Cilium
    - name: Download Cilium CLI
      get_url:
        url: https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz
        dest: /tmp/cilium-cli.tar.gz

    - name: Extract Cilium CLI
      unarchive:
        src: /tmp/cilium-cli.tar.gz
        dest: /usr/local/bin
        remote_src: yes

    - name: Install Cilium with LoadBalancer and Gateway API support
      become: false
      shell: |
        cilium install --version {{ cilium_version }} \
          --set l2announcements.enabled=true \
          --set l2announcements.leaseDuration=3s \
          --set l2announcements.leaseRenewDeadline=1s \
          --set l2announcements.leaseRetryPeriod=500ms \
          --set kubeProxyReplacement=true \
          --set k8sServiceHost={{ node_ip_public }} \
          --set k8sServicePort=6443 \
          --set ipv4NativeRoutingCIDR={{ pod_network }} \
          --set routingMode=tunnel \
          --set devices='{enp0s8,enp0s9}' \
          --set gatewayAPI.enabled=true
      environment:
        KUBECONFIG: /home/vagrant/.kube/config
      when: init_result is changed

    - name: Wait for Cilium to be ready
      become: false
      shell: cilium status --wait
      environment:
        KUBECONFIG: /home/vagrant/.kube/config
      when: init_result is changed
      retries: 30
      delay: 10
      register: cilium_status
      until: cilium_status.rc == 0

    # Configure Cilium LoadBalancer
    - name: Generate Cilium LoadBalancer IP pool manifest from template
      template:
        src: "templates/cilium-lb-ippool.yaml.j2"
        dest: "/tmp/cilium-lb-ippool.yaml"
      when: init_result is changed

    - name: Copy Cilium L2 announcement policy
      copy:
        src: "../manifests/cilium/cilium-l2-announcement.yaml"
        dest: "/tmp/cilium-l2-announcement.yaml"
      when: init_result is changed

    - name: Apply Cilium LoadBalancer IP Pool
      become: false
      shell: kubectl apply -f /tmp/cilium-lb-ippool.yaml
      environment:
        KUBECONFIG: /home/vagrant/.kube/config
      when: init_result is changed

    - name: Apply Cilium L2 Announcement Policy
      become: false
      shell: kubectl apply -f /tmp/cilium-l2-announcement.yaml
      environment:
        KUBECONFIG: /home/vagrant/.kube/config
      when: init_result is changed

    # Generate join command
    - name: Generate join command
      shell: kubeadm token create --print-join-command
      register: join_command
      when: init_result is changed

    - name: Save join command
      copy:
        content: "{{ join_command.stdout }}"
        dest: /tmp/join-command
      when: init_result is changed

    - name: Fetch join command
      fetch:
        src: /tmp/join-command
        dest: /tmp/join-command
        flat: yes
      when: init_result is changed

    # Node cleanup cron job
    - name: Deploy cleanup script
      template:
        src: "templates/cleanup-node.sh.j2"
        dest: "/usr/local/bin/cleanup-node.sh"
        mode: '0755'

    - name: Setup cleanup cron job (every hour)
      cron:
        name: "Kubernetes node cleanup"
        minute: "0"
        job: "/usr/local/bin/cleanup-node.sh"
        user: root
